# 4.2 Example#2

### Lasagne+Nolearn MNIST Example<sup style="font-size:12px;">[[10]](#ref10)[[11]](#ref11)</sup>
```python
#!/usr/bin/env python

import lasagne
from lasagne import layers
from lasagne.updates import nesterov_momentum
from nolearn.lasagne import NeuralNet

import sys
import os
import gzip
import pickle
import numpy


PY2 = sys.version_info[0] == 2

if PY2:
    from urllib import urlretrieve

    def pickle_load(f, encoding):
        return pickle.load(f)
else:
    from urllib.request import urlretrieve

    def pickle_load(f, encoding):
        return pickle.load(f, encoding=encoding)

DATA_URL = 'http://deeplearning.net/data/mnist/mnist.pkl.gz'
DATA_FILENAME = 'mnist.pkl.gz'


def _load_data(url=DATA_URL, filename=DATA_FILENAME):
    """Load data from `url` and store the result in `filename`."""
    if not os.path.exists(filename):
        print("Downloading MNIST dataset")
        urlretrieve(url, filename)

    with gzip.open(filename, 'rb') as f:
        return pickle_load(f, encoding='latin-1')


def load_data():
    """Get data with labels, split into training, validation and test set."""
    data = _load_data()
    X_train, y_train = data[0]
    X_valid, y_valid = data[1]
    X_test, y_test = data[2]
    y_train = numpy.asarray(y_train, dtype=numpy.int32)
    y_valid = numpy.asarray(y_valid, dtype=numpy.int32)
    y_test = numpy.asarray(y_test, dtype=numpy.int32)

    return dict(
        X_train=X_train,
        y_train=y_train,
        X_valid=X_valid,
        y_valid=y_valid,
        X_test=X_test,
        y_test=y_test,
        num_examples_train=X_train.shape[0],
        num_examples_valid=X_valid.shape[0],
        num_examples_test=X_test.shape[0],
        input_dim=X_train.shape[1],
        output_dim=10,
    )


def nn_example(data):
    net1 = NeuralNet(
        layers=[('input', layers.InputLayer),
                ('hidden', layers.DenseLayer),
                ('output', layers.DenseLayer),
                ],
        # layer parameters:
        input_shape=(None, 28*28),
        hidden_num_units=100,  # number of units in 'hidden' layer
        output_nonlinearity=lasagne.nonlinearities.softmax,
        output_num_units=10,  # 10 target values for the digits 0, 1, 2, ..., 9

        # optimization method:
        update=nesterov_momentum,
        update_learning_rate=0.01,
        update_momentum=0.9,

        max_epochs=10,
        verbose=1,
        )

    # Train the network
    net1.fit(data['X_train'], data['y_train'])

    # Try the network on new data
    print("Feature vector (100-110): %s" % data['X_test'][0][100:110])
    print("Label: %s" % str(data['y_test'][0]))
    print("Predicted: %s" % str(net1.predict([data['X_test'][0]])))


def main():
    data = load_data()
    print("Got %i testing datasets." % len(data['X_train']))
    nn_example(data)

if __name__ == '__main__':
    main()
```
測試結果：
```
Got 50000 testing datasets.
# Neural Network with 79510 learnable parameters

## Layer information

  #  name      size
---  ------  ------
  0  input      784
  1  hidden     100
  2  output      10

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  ----   -
      1     0.60817     0.32911    1.84796      0.90925  0.23   s
      2     0.31281     0.26981    1.15938      0.92364  0.22   s
      3     0.25968     0.23361    1.11160      0.93413  0.22   s
      4     0.22340     0.20855    1.07121      0.94093  0.23   s
      5     0.19677     0.19023    1.03438      0.94513  0.24   s
      6     0.17600     0.17600    1.00001      0.95002  0.25   s
      7     0.15927     0.16473    0.96688      0.95312  0.25   s
      8     0.14554     0.15572    0.93461      0.95632  0.25   s
      9     0.13394     0.14833    0.90296      0.95702  0.25   s
     10     0.12406     0.14209    0.87311      0.95962  0.26   s
Feature vector (100-110): [ 0.  0.  0.  0.  0.  0.  0.  0.  0   .  0.]
Label: 7
Predicted: [7]

```

---
<sup id="ref10">[10]</sup> [Best python library for neural networks](http://datascience.stackexchange.com/questions/694/best-python-library-for-neural-networks)

<sup id="ref11">[11]</sup> [用Lasagne来实现MLP，测试mnist](http://www.voidcn.com/blog/taneijia/article/p-4394548.html)